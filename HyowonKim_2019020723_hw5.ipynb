{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> __ Provided on May 27 and due on June 17__ [BRI516, Spring/2019] </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For homework in general:\n",
    "* Install `Anaconda` and create an environment with `NumPy`, `Pandas`, `Matplotlib`, `scikit-learn` in Python 3.5 \n",
    "* Please upload your jupyter-notebook file for homework to `Blackboard`\n",
    "* Please visualize the results as much as possible and discuss your results at least one line of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Disable warning message\n",
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import library & module\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import struct\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Hw05] Implementing a Multilayer Neural Networks using TensorFlow (TF) 1.x (Ch. 13)\n",
    "\n",
    "\n",
    "##### (1) Data preparation\n",
    "    (1a) Load the train dataset and test dataset of the MNIST \n",
    "    \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-f427242af978>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/hyo1kim/.conda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/hyo1kim/.conda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./data/mnist/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/hyo1kim/.conda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./data/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/hyo1kim/.conda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "## import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist_data = input_data.read_data_sets(\"./data/mnist/\", validation_size=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    (1b) Set the first 55,000 samples in the training dataset as training data, the remaining 5,000 samples in the training dataset as validation data, and 10,000 samples in the test dataset as test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data\n",
      " rows: 55000, columns: 784\n",
      "validation data\n",
      " rows: 5000, columns: 784\n",
      "test data\n",
      " rows: 10000, columns: 784\n"
     ]
    }
   ],
   "source": [
    "## Set the first 55,000 samples in the training dataset as training data\n",
    "X_train = mnist_data.train.images\n",
    "y_train = mnist_data.train.labels\n",
    "print('training data\\n rows: %d, columns: %d' % (X_train.shape[0], X_train.shape[1]))\n",
    "\n",
    "# the remaining 5,000 samples in the training dataset as validation data\n",
    "X_valid = mnist_data.validation.images\n",
    "y_valid = mnist_data.validation.labels\n",
    "print('validation data\\n rows: %d, columns: %d' % (X_valid.shape[0], X_valid.shape[1]))\n",
    "\n",
    "# 10,000 samples in the test dataset as test data\n",
    "X_test = mnist_data.test.images\n",
    "y_test = mnist_data.test.labels\n",
    "print('test data\\n rows: %d, columns: %d' % (X_test.shape[0], X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check\n",
    "fig, ax = plt.subplots(nrows=2, ncols=5, sharex=True, sharey=True,)\n",
    "ax = ax.flatten()\n",
    "for i in range(10):\n",
    "    img = X_train[y_train == i][0].reshape(28, 28)\n",
    "    ax[i].imshow(img, cmap='Greys')\n",
    "    \n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 784) (55000,)\n",
      "(5000, 784) (5000,)\n",
      "(10000, 784) (10000,)\n"
     ]
    }
   ],
   "source": [
    "## mean centering and normalization:\n",
    "mean_vals = np.mean(X_train, axis=0)\n",
    "std_val = np.std(X_train)\n",
    "\n",
    "X_train_centered = (X_train - mean_vals)/std_val\n",
    "X_valid_centered = (X_valid - mean_vals)/std_val\n",
    "X_test_centered = (X_test - mean_vals)/std_val\n",
    "\n",
    "del X_train, X_test, X_valid\n",
    "\n",
    "print(X_train_centered.shape, y_train.shape)\n",
    "print(X_valid_centered.shape, y_valid.shape)\n",
    "print(X_test_centered.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (2) Multilayer perceptron (MLP) using the low-level API of TF (e.g., p. 429)\n",
    "    (2a) Implement the multilayer perceptron (MLP) with two hidden layers for classification, and evaluate performance in the following scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        (2a-1) for a few choices of hidden nodes per hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch_generator(X, y, batch_size=1, shuffle=False):\n",
    "    X_copy = np.array(X)\n",
    "    y_copy = np.array(y)\n",
    "    \n",
    "    if shuffle:\n",
    "        data = np.column_stack((X_copy, y_copy))\n",
    "        np.random.shuffle(data)\n",
    "        X_copy = data[:, :-1]\n",
    "        y_copy = data[:, -1].astype(int)\n",
    "        \n",
    "    for i in range(0, X.shape[0], batch_size):\n",
    "        yield (X[i:i+batch_size, :], y[i:i+batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 미리 코드상에는 2a), 2b) 2c) 구현 다 해놓은 후 각각을 값을 줘서 실행할 수 있는 코드로 설정\n",
    "class MLP(object):    \n",
    "    def __init__(self, n_features, epochs=10, learning_rate=0.001, l2= 0, n_hidden=32, batch_size=1, shuffle=False, random_seed=None, activation_fn='sigmoid'):\n",
    "        np.random.seed(random_seed)\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.shuffle = shuffle\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_features = n_features\n",
    "        self.valid_acc_ = 0.0\n",
    "        self.train_loss_ = 0.0\n",
    "        self.output_ = 0.0\n",
    "        self.l2 = l2\n",
    "        self.batch_size = batch_size\n",
    "        if activation_fn == 'sigmod':\n",
    "            self.activation = tf.nn.sigmoid\n",
    "        elif activation_fn == 'tanh':\n",
    "            self.activation = tf.nn.tanh\n",
    "        elif activation_fn == 'relu':\n",
    "            self.activation = tf.nn.relu\n",
    "        else: # default\n",
    "            self.activation = tf.nn.sigmoid\n",
    "            \n",
    "        self.test=0.\n",
    "                \n",
    "        g = tf.Graph()\n",
    "        with g.as_default():\n",
    "            ## set random-seed:\n",
    "            tf.set_random_seed(random_seed)\n",
    "            \n",
    "            ## build the network:\n",
    "            self.build()\n",
    "            \n",
    "            ## initializer\n",
    "            self.init_op = tf.global_variables_initializer()\n",
    "            \n",
    "        ## create a session\n",
    "        self.sess = tf.Session(graph=g)\n",
    "    \n",
    "    def build(self):\n",
    "        n_classes = 10\n",
    "        \n",
    "        ## Placeholders for X and y:\n",
    "        tf_x = tf.placeholder(dtype=tf.float32, shape=(None, n_features), name='tf_x')\n",
    "        tf_y = tf.placeholder(dtype=tf.int32, shape=None, name='tf_y')\n",
    "        \n",
    "        ## One-hot encoding:\n",
    "        y_onehot = tf.one_hot(indices=tf_y, depth=n_classes)\n",
    "        \n",
    "        ## Store layers weight & bias\n",
    "        weights = {\n",
    "        'h1': tf.Variable(tf.random_normal([self.n_features, self.n_hidden])),\n",
    "        'h2': tf.Variable(tf.random_normal([self.n_hidden, self.n_hidden])),\n",
    "        'out': tf.Variable(tf.random_normal([self.n_hidden, n_classes]))\n",
    "        }\n",
    "        biases = {\n",
    "            'b1': tf.Variable(tf.random_normal([self.n_hidden])),\n",
    "            'b2': tf.Variable(tf.random_normal([self.n_hidden])),\n",
    "            'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "        }\n",
    "            \n",
    "        ## 1st layer(Hidden#1)\n",
    "        layer_1 = self.activation(tf.add(tf.matmul(tf_x, weights['h1']), biases['b1']))\n",
    "        \n",
    "        ## 2nd layer(Hidden#2)\n",
    "        layer_2 = self.activation(tf.add(tf.matmul(layer_1, weights['h2']), biases['b2']))\n",
    "        \n",
    "        ## output\n",
    "        logits = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "        self.output_ = logits\n",
    "        \n",
    "        ## Prediction\n",
    "        predictions = {\n",
    "            #'classes' : tf.argmax(logits, axis=1, name='predicted_classes'),\n",
    "            'probabilities' : tf.nn.softmax(logits, name='softmax_tensor'),\n",
    "            'labels' : tf.cast(tf.argmax(logits, axis=1), tf.int32, name='labels')\n",
    "        }\n",
    "        \n",
    "        ## Loss Function and Optimization\n",
    "        regularizer = (self.l2 / 2) * (tf.reduce_mean(tf.square(weights['h1'])) + tf.reduce_mean(tf.square(weights['h2'])))\n",
    "        cross_entropy_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y_onehot),name='cross_entropy_loss')\n",
    "        cross_entropy_loss_l2 = tf.add(cross_entropy_loss, regularizer, name='cross_entropy_loss_l2')\n",
    "        \n",
    "        ## Optimizer:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=self.learning_rate)\n",
    "        optimizer = optimizer.minimize(cross_entropy_loss_l2, name='train_op')\n",
    "        \n",
    "        ## Finding accuracy\n",
    "        correct_predictions = tf.equal(predictions['labels'], tf_y, name='correct_preds')\n",
    "        \n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32), name='accuracy')\n",
    "        \n",
    "    def train(self, training_set, validation_set=None, initialize=True):\n",
    "        ## initialize variables\n",
    "        if initialize:\n",
    "            self.sess.run(self.init_op)\n",
    "        \n",
    "        self.train_cost_ = []\n",
    "        X_data = np.array(training_set[0])\n",
    "        y_data = np.array(training_set[1])\n",
    "        \n",
    "        if self.batch_size > 1:\n",
    "            self.shuffle = True\n",
    "                \n",
    "        for epoch in range(1, self.epochs + 1):\n",
    "            batch_gen = create_batch_generator(X_train_centered, y_train, batch_size=self.batch_size, shuffle=self.shuffle)\n",
    "            \n",
    "            avg_loss = 0.0\n",
    "            for i, (batch_x,batch_y) in enumerate(batch_gen):\n",
    "                feed = {'tf_x:0': batch_x, 'tf_y:0': batch_y}\n",
    "                loss, _ = self.sess.run(['cross_entropy_loss:0', 'train_op'], feed_dict=feed)\n",
    "                avg_loss += loss\n",
    "                \n",
    "            self.train_loss_ = avg_loss\n",
    "            print('Epoch %02d: Training Avg. Loss: ' '%7.3f' % (epoch, avg_loss), end=' ')\n",
    "            \n",
    "            if validation_set is not None:\n",
    "                feed = {'tf_x:0': validation_set[0], 'tf_y:0': validation_set[1]}\n",
    "                valid_acc = self.sess.run('accuracy:0', feed_dict=feed)\n",
    "                self.valid_acc_ = valid_acc\n",
    "                print('Validation Acc: %7.3f' % self.valid_acc_)\n",
    "            else:\n",
    "                self.valid_acc_ = 0.0\n",
    "                print()\n",
    "                \n",
    "        def predict(self, X_test, return_proba = False):\n",
    "            feed = {'tf_x:0': X_test}\n",
    "            if return_proba:\n",
    "                return self.sess.run('probabilities:0', feed_dict=feed)\n",
    "            else:\n",
    "                return self.sess.run('labels:0', feed_dict=feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## global varaibles : n_features\n",
    "n_features = X_train_centered.shape[1]\n",
    "n_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-df1ca6f9607a>:81: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "======== hidden size : 32 ========\n",
      "Epoch 01: Training Avg. Loss: 101016.524 Validation Acc:   0.571\n",
      "======== hidden size : 64 ========\n",
      "Epoch 01: Training Avg. Loss: 93909.073 Validation Acc:   0.665\n",
      "======== hidden size : 128 ========\n",
      "Epoch 01: Training Avg. Loss: 117630.346 Validation Acc:   0.707\n",
      "======== hidden size : 256 ========\n",
      "Epoch 01: Training Avg. Loss: 137716.969 Validation Acc:   0.728\n",
      "======== hidden size : 512 ========\n",
      "Epoch 01: Training Avg. Loss: 162072.002 Validation Acc:   0.784\n",
      "======== hidden size : 1024 ========\n",
      "Epoch 01: Training Avg. Loss: 205268.536 Validation Acc:   0.808\n",
      "\n",
      "** best hidden node : 1024\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## a few choices of hidden nodes per hidden layer\n",
    "hidden_nodes = [32, 64, 128, 256, 512, 1024]\n",
    "val_accs_0 = []\n",
    "for n_hidden in hidden_nodes:\n",
    "    mlp = MLP(n_hidden=n_hidden, n_features=n_features, random_seed=123, epochs=n_epochs)\n",
    "    \n",
    "    print('======== hidden size : %d ========' % n_hidden)\n",
    "    mlp.train(training_set=(X_train_centered, y_train), validation_set=(X_valid_centered, y_valid))\n",
    "    \n",
    "    val_accs_0.append(mlp.valid_acc_)\n",
    "    \n",
    "max_index = val_accs_0.index(max(val_accs_0))\n",
    "best_hidden = hidden_nodes[max_index]\n",
    "print('\\n** best hidden node : %d' % best_hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        (2a-2) for a few choices of activation functions (i.e., sigmoid, tanh, and ReLU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== activation function : sigmoid ========\n",
      "Epoch 01: Training Avg. Loss: 205268.536 Validation Acc:   0.808\n",
      "======== activation function : tanh ========\n",
      "Epoch 01: Training Avg. Loss: 427974.795 Validation Acc:   0.832\n",
      "======== activation function : relu ========\n"
     ]
    }
   ],
   "source": [
    "## a few choices of activation functions\n",
    "activations = ['sigmoid', 'tanh', 'relu']\n",
    "val_accs_1 = []\n",
    "for activation_fn in activations:\n",
    "    mlp_act = MLP(n_hidden=best_hidden, activation_fn=activation_fn, random_seed=123, epochs=n_epochs, n_features=n_features)\n",
    "    \n",
    "    print('======== activation function : %s ========' % activation_fn)\n",
    "    mlp_act.train(training_set=(X_train_centered, y_train), validation_set=(X_valid_centered, y_valid))\n",
    "    \n",
    "    val_accs_1.append(mlp_act.valid_acc_)\n",
    "    \n",
    "max_index = val_accs_1.index(max(val_accs_1))\n",
    "best_activation = activations[max_index]\n",
    "print('\\n** best activation function : %s' % best_activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "      (2b) Add the L2-norm regularization of weights to (2a) and evalute performance for a few choices of L2-norm regularization parameters. For this, please pick the best-performing model from (2a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## a few choices of L2-norm regularization parameters\n",
    "l2_weight_decays = [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
    "val_accs_2 = []\n",
    "for l2_weight_decay in l2_weight_decays:\n",
    "    mlp_l2 = MLP(n_hidden=best_hidden, activation_fn=best_activation, l2=l2_weight_decay, epochs=n_epochs, n_features=n_features, random_seed=123)\n",
    "    \n",
    "    print('======== L2-norm regularization of weights : %f ========' % l2_weight_decay)\n",
    "    mlp_l2.train(training_set=(X_train_centered, y_train), validation_set=(X_valid_centered, y_valid))\n",
    "    \n",
    "    val_accs_2.append(mlp_l2.valid_acc_)\n",
    "    \n",
    "max_index = val_accs_2.index(max(val_accs_2))\n",
    "best_weight = l2_weight_decays[max_index]\n",
    "print('\\n** best L2-norm regularization of weights: %f' % best_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    (2c) Evaluate the performance of (2b) for a few options of mini-batch sizes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## a few options of mini-batch sizes\n",
    "batch_sizes = [4, 8, 16, 32, 64, 128]\n",
    "val_accs_3 = []\n",
    "for n_batch_size in batch_sizes:\n",
    "    mlp_batch = MLP(n_hidden=best_hidden, activation_fn=best_activation, l2=l2_weight_decay, batch_size=n_batch_size, epochs=n_epochs, n_features=n_features, random_seed=123)\n",
    "    \n",
    "    print('======== mini-batch sizes : %d ========' % n_batch_size)\n",
    "    mlp_batch.train(training_set=(X_train_centered, y_train), validation_set=(X_valid_centered, y_valid))\n",
    "    \n",
    "    val_accs_3.append(mlp_batch.valid_acc_)\n",
    "    \n",
    "max_index = val_accs_3.index(max(val_accs_3))\n",
    "best_batch = batch_sizes[max_index]\n",
    "print('\\n** best mini-batch sizes: %d' % best_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    (2d) Commonly for the results for (2a) - (2c), discuss the results such as by presenting convergence curves of cost and/or accuracy and by exemplifying the misclassified digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_misclassified(X, y, misclassified, predicted):\n",
    "    fig = plt.figure('misclassified digits', figsize=(10, 10))    \n",
    "    for i in range(10):\n",
    "        subplot = fig.add_subplot(2, 5, i+1)            \n",
    "        subplot.set_xticks([])\n",
    "        subplot.set_yticks([])            \n",
    "        subplot.set_title('ground truth : %d\\npredicted : %d' % (y[misclassified[i]], predicted[misclassified[i]]))            \n",
    "        subplot.imshow(X[misclassified[i], :].reshape((28, 28)), cmap=plt.cm.gray_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## a few choices of hidden nodes per hidden layer\n",
    "plt.plot(hidden_nodes, val_accs_0, label='acc per hidden nodes')\n",
    "plt.xlabel('hidden_size')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()\n",
    "\n",
    "preds0 = mlp.predict(X_test_centered)\n",
    "print('Test Accuracy(hidden nodes): %.2f%%' % (100*np.sum(y_test == preds0)/len(y_test)))\n",
    "\n",
    "misclassified = np.where(preds0 != y_test)[0]\n",
    "plot_misclassified(X_test_centered, y_test, misclassified, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## a few choices of activation functions\n",
    "plt.plot([0, 1, 2], val_accs_1, label='acc per activation functions')\n",
    "plt.xlabel('activation functions (0:sigmoid, 1:tanh, 2:relu)')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()\n",
    "\n",
    "preds1 = mlp_act.predict(X_test_centered)\n",
    "print('Test Accuracy(hidden nodes+activation): %.2f%%' % (100*np.sum(y_test == preds1)/len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## a few choices of L2-norm regularization parameters\n",
    "plt.plot(l2_weight_decays, val_accs_2, label='acc per L2-norm regularization weight')\n",
    "plt.xlabel('L2-norm regularization weight')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()\n",
    "\n",
    "preds2 = mlp_l2.predict(X_test_centered)\n",
    "print('Test Accuracy(hidden nodes+activation+L2-norm): %.2f%%' % (100*np.sum(y_test == preds2)/len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## a few options of mini-batch sizes\n",
    "plt.plot(batch_sizes, val_accs_3, label='acc per mini-batch sizes')\n",
    "plt.xlabel('mini-batch sizes')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()\n",
    "\n",
    "preds3 = mlp_batch.predict(X_test_centered)\n",
    "print('Test Accuracy(hidden nodes+activation+L2-norm+mini-batch): %.2f%%' % (100*np.sum(y_test == preds3)/len(y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
